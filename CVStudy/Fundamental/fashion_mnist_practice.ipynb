{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "colab": {
      "name": "fashion-mnist-practice.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hphp777/GraduationProject01/blob/main/CVStudy/Fundamental/fashion_mnist_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Qvyjnn0zYl39"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL5wxoTPYl4E"
      },
      "source": [
        "### Keras fashion mnist dataset을 다운로드\n",
        "* 5만개의 학습용, 1만개의 테스트용 grayscale image array를 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gmx2JR_gYl4G"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# 전체 6만개 데이터 중, 5만개는 학습 데이터용, 1만개는 테스트 데이터용으로 분리\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "# image size는 28x28의 grayscale 2차원 데이터\n",
        "print(\"train dataset shape:\", train_images.shape, train_labels.shape)\n",
        "print(\"test dataset shape:\", test_images.shape, test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md_5oA9xYl4H"
      },
      "source": [
        "### MNIST image array 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vtxipbEYYl4I"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(train_images[0], cmap='gray')\n",
        "plt.title(train_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-WG61HaFYl4J"
      },
      "source": [
        "train_images[0, :, :], train_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9eTlmHpnYl4K"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "def show_images(images, labels, ncols=8):\n",
        "    figure, axs = plt.subplots(figsize=(22, 6), nrows=1, ncols=ncols)\n",
        "    for i in range(ncols):\n",
        "        axs[i].imshow(images[i], cmap='gray')\n",
        "        axs[i].set_title(class_names[labels[i]])\n",
        "        \n",
        "show_images(train_images[:8], train_labels[:8], ncols=8)\n",
        "show_images(train_images[8:16], train_labels[8:16], ncols=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67ZemdYl4L"
      },
      "source": [
        "### 데이터 전처리 수행. \n",
        "* 0 ~ 255 사이의 픽셀값을 0 ~ 1 사이 값으로 변환. \n",
        "* array type은 float 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qXvpQxUgYl4M"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "def get_preprocessed_data(images, labels):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    images = np.array(images/255.0, dtype=np.float32)\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "train_images, train_labels = get_preprocessed_data(train_images, train_labels)\n",
        "test_images, test_labels = get_preprocessed_data(test_images, test_labels)\n",
        "\n",
        "print(\"train dataset shape:\", train_images.shape, train_labels.shape)\n",
        "print(\"test dataset shape:\", test_images.shape, test_labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PhA0xoWOYl4O"
      },
      "source": [
        "train_images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpjUzAlPYl4O"
      },
      "source": [
        "### Dense Layer를 기반으로 모델을 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oNAuY-VPYl4P"
      },
      "source": [
        "INPUT_SIZE = 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-FXaCnvYYl4Q"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCZlqE7FYl4R"
      },
      "source": [
        "### 모델의 Loss와 Optimizer 설정하고 학습 수행\n",
        "* loss는 categorical_crossentropy로, optimizer는 Adam으로 설정\n",
        "* categorical crossentropy를 위해서 Lable을 OHE 로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nxQyfSKLYl4S"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import Accuracy\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Cn5art90Yl4U"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "train_oh_labels = to_categorical(train_labels)\n",
        "test_oh_labels = to_categorical(test_labels)\n",
        "\n",
        "print(train_oh_labels.shape, test_oh_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yJLJrDMWYl4V"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D3vjCk3MYl4V"
      },
      "source": [
        "history = model.fit(x=train_images, y=train_oh_labels, batch_size=32, epochs=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kJ4gGdqiYl4W"
      },
      "source": [
        "print(history.history['loss'])\n",
        "print(history.history['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6RNpzGCYl4W"
      },
      "source": [
        "### 테스트 데이터를 기반으로 Label 값 예측\n",
        "* model.predict()를 이용하여 label값 예측\n",
        "* predict()의 인자로 입력되는 feature array는 학습의 feature array와 shape가 동일해야함. \n",
        "* fit() 시 3차원(28x28 2차원 array가 여러개 존재) array 입력 했으므로 predict()도 동일한 3차원 데이터 입력\n",
        "* 특히 한건만 predict() 할때도 3차원 데이터여야 함. 이를 위해 expand_dims()로 2차원 image 배열을 3차원으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cWlkRCDLYl4X"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YKCBp8G2Yl4Y"
      },
      "source": [
        "pred_proba = model.predict(test_images)\n",
        "print(pred_proba.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E8EME9wgYl4Y"
      },
      "source": [
        "np.expand_dims(test_images[0], axis=0).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CGFJdzuTYl4Z"
      },
      "source": [
        "pred_proba = model.predict(np.expand_dims(test_images[0], axis=0))\n",
        "print('softmax output:', pred_proba)\n",
        "pred = np.argmax(np.squeeze(pred_proba))\n",
        "print('predicted class value:', pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9h5AFwqfYl4a"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "print('target class value:', test_labels[0], 'predicted class value:', pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfUgFtulYl4a"
      },
      "source": [
        "### 테스트 데이터 세트로 모델 성능 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "59JO6CCKYl4b"
      },
      "source": [
        "model.evaluate(test_images, test_oh_labels, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eDmuMmh8Yl4b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDhm5OkfYl4c"
      },
      "source": [
        "### 검증 데이터 세트를 이용하여 학습 수행. \n",
        "* 일반적으로 fit() 수행시 별도의 검증 데이터 세트를 이용하여 학습 시 과적합(Overfitting)이 발생하는지 모니터링\n",
        "* fit()을 수행하면 iteration을 반복하기 때문에 중간에 하이퍼파라미터 변경(예: Learning Rate)등의 작업이 어려움. \n",
        "* fit() iteration시 여러 작업을 하기 위해 Callback 객체를 가짐. \n",
        "* 검증 데이터 세트를 fit() 시 적용하여 과적합이나 더이상 검증 데이터 성능이 좋아 지지 않을 때 Callback을 사용하여 Learning Rate 보정 작업등을 수행 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8xVtDH6EYl4d"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "def get_preprocessed_data(images, labels):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    images = np.array(images/255.0, dtype=np.float32)\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "train_images, train_labels = get_preprocessed_data(train_images, train_labels)\n",
        "test_images, test_labels = get_preprocessed_data(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VWn1-UdoYl4e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 기존 학습 데이터를 다시 학습과 검증 데이터 세트로 분리\n",
        "tr_images, val_images, tr_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.15, random_state=2021)\n",
        "print('train과 validation shape:', tr_images.shape, tr_labels.shape, val_images.shape, val_labels.shape)\n",
        "\n",
        "# OHE 적용\n",
        "tr_oh_labels = to_categorical(tr_labels)\n",
        "val_oh_labels = to_categorical(val_labels)\n",
        "\n",
        "print('after OHE:', tr_oh_labels.shape, val_oh_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycyUW7NNYl4f"
      },
      "source": [
        "### 검증 데이터 세트를 적용하여 학습 수행. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c-gNkQUVYl4f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oM1ugKgqYl4g"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "INPUT_SIZE = 28\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6dy6xS2PYl4g"
      },
      "source": [
        "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, validation_data=(val_images, val_oh_labels), \n",
        "                    epochs=20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mYNI9zlHYl4h"
      },
      "source": [
        "print(history.history['loss'])\n",
        "print(history.history['accuracy'])\n",
        "print(history.history['val_loss'])\n",
        "print(history.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZBwgVCbiYl4h"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='valid')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYoWklIIYl4i"
      },
      "source": [
        "### Functional API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ijnhyt82Yl4i"
      },
      "source": [
        "# Sequential Model을 이용하여 Keras 모델 생성 \n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "INPUT_SIZE = 28\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dense(30, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Flatten(input_shape=(INPUT_SIZE, INPUT_SIZE)))\n",
        "model1.add(Dense(100, activation='relu'))\n",
        "model1.add(Dense(30, activation='relu'))\n",
        "model1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model1.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B-LxdgF9Yl4j"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
        "x = Flatten()(input_tensor)\n",
        "x = Dense(100, activation='relu')(x)\n",
        "x = Dense(30, activation='relu')(x)\n",
        "output = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6F1Cq2qYl4j"
      },
      "source": [
        "### Custom한 Dense Layer 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SxvbAWyJYl4k"
      },
      "source": [
        "from tensorflow.keras.layers import Layer, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "class CustomDense(tf.keras.layers.Layer):\n",
        "    # CustomDense 객체 생성시 입력되는 초기화 parameter 처리\n",
        "    def __init__(self, units=32):\n",
        "        super(CustomDense, self).__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.w = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer=\"random_normal\",\n",
        "            trainable=True,\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
        "        )\n",
        "        \n",
        "    # CustomDense 객체에 callable로 입력된 입력 데이터 처리. \n",
        "    def call(self, inputs):\n",
        "        return tf.matmul(inputs, self.w) + self.b\n",
        "\n",
        "# input 값을 4개의 원소를 가지는 1차원으로 생성. \n",
        "inputs = Input((4,))\n",
        "# 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력 \n",
        "outputs = CustomDense(10)(inputs)\n",
        "\n",
        "# inputs와 outputs로 model 생성. \n",
        "model = Model(inputs, outputs)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F8Xx1MNYl4l"
      },
      "source": [
        "### Functional API는 객체 생성 부분과 Callable 인자 입력 부분을 별도로 수행해도 무방. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BL7rC2mPYl4m"
      },
      "source": [
        "inputs = Input((4,))\n",
        "# 10개의 unit을 가지는 CustomDense 객체를 생성 후 callable로 inputs값 입력 \n",
        "my_layer = CustomDense(10)\n",
        "outputs = my_layer(inputs)\n",
        "\n",
        "# inputs와 outputs로 model 생성. \n",
        "model = Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfTZxq88Yl4m"
      },
      "source": [
        "### Sequential Model 생성은 단지 Functional API Layer들을 iteration 하면서 연결한 것을 model로 만든 것임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "InhZV2ZIYl4n"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential([Input((4,)),\n",
        "                   CustomDense(10),\n",
        "                   CustomDense(8), \n",
        "                   tf.keras.layers.ReLU()])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4DmaSoAYl4n"
      },
      "source": [
        "### Sequential Model을 Functional 객체를 For loop 반복 호출하여 작성."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XVCoR81kYl4o"
      },
      "source": [
        "layers_list = [Input((4,)), CustomDense(10), CustomDense(8), tf.keras.layers.ReLU()]\n",
        "\n",
        "for index, layer in enumerate(layers_list):\n",
        "        print(index, layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rjktHllVYl4p"
      },
      "source": [
        "layers_list = [Input((4,)), CustomDense(10), CustomDense(8), tf.keras.layers.ReLU()]\n",
        "\n",
        "inputs = None\n",
        "callable_inputs = None\n",
        "outputs = None\n",
        "# layers_list에 있는 Functional 객체를 iteration 수행하면서 적용. \n",
        "for index, layer in enumerate(layers_list):\n",
        "    # layers_list의 첫번째 인자는 Input 간주. \n",
        "    if index == 0:\n",
        "        inputs = layer\n",
        "        callable_inputs = layer\n",
        "    # Functional 객체에 callable 인자로 callable_inputs를 입력하고 반환 결과 값을 다시 callable_inputs로 할당.     \n",
        "    else: \n",
        "        callable_inputs = layer(callable_inputs)\n",
        "    \n",
        "outputs = callable_inputs\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju4QFcjPYl4p"
      },
      "source": [
        "### 앞에서 생성한 로직들을 함수화 \n",
        "* Functional API로 모델 만들기\n",
        "* pixel값 1 ~ 255를 0 ~ 1사이값 Float 32로 만들기\n",
        "* One Hot Encoding Label에 적용하기\n",
        "* 학습과 검증 데이터로 나누기.\n",
        "* compile, 학습/예측/평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LShPkhAAYl4q"
      },
      "source": [
        "from tensorflow.keras.layers import Layer, Input, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "INPUT_SIZE = 28\n",
        "\n",
        "def create_model():\n",
        "    input_tensor = Input(shape=(INPUT_SIZE, INPUT_SIZE))\n",
        "    x = Flatten()(input_tensor)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    x = Dense(30, activation='relu')(x)\n",
        "    output = Dense(10, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs=input_tensor, outputs=output)\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3Mnu7-X9Yl4q"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0 ~ 1사이값의 float32로 변경하는 함수\n",
        "def get_preprocessed_data(images, labels):\n",
        "    \n",
        "    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n",
        "    images = np.array(images/255.0, dtype=np.float32)\n",
        "    labels = np.array(labels, dtype=np.float32)\n",
        "    \n",
        "    return images, labels\n",
        "\n",
        "# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n",
        "def get_preprocessed_ohe(images, labels):\n",
        "    images, labels = get_preprocessed_data(images, labels)\n",
        "    # OHE 적용 \n",
        "    oh_labels = to_categorical(labels)\n",
        "    return images, oh_labels\n",
        "\n",
        "# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n",
        "def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n",
        "    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n",
        "    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n",
        "    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n",
        "    \n",
        "    # 학습 데이터를 검증 데이터 세트로 다시 분리\n",
        "    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n",
        "    \n",
        "    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lAaN_q39Yl4r"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "# Fashion MNIST 데이터 재 로딩 및 전처리 적용하여 학습/검증/데이터 세트 생성. \n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n",
        "(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n",
        "    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n",
        "print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zZi2zWgLYl4s"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Model 생성 및 optimizer, loss, metric 적용\n",
        "model = create_model()\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UZCoHxLrYl4t"
      },
      "source": [
        "# 학습 수행. \n",
        "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=20, validation_data=(val_images, val_oh_labels))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DyInIwuDYl4t"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def show_history(history):\n",
        "    plt.plot(history.history['accuracy'], label='train')\n",
        "    plt.plot(history.history['val_accuracy'], label='valid')\n",
        "    plt.legend()\n",
        "    \n",
        "show_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lJFDrQ4hYl4u"
      },
      "source": [
        "# 테스트 데이터 세트로 모델 성능 검증\n",
        "model.evaluate(test_images, test_oh_labels, batch_size=256, verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrXbY3v0Yl4u"
      },
      "source": [
        "### Callback "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngrZAMuMYl4v"
      },
      "source": [
        "#### ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "* 특정 조건에 맞춰서 모델을 파일로 저장\n",
        "* filepath: filepath는 (on_epoch_end에서 전달되는) epoch의 값과 logs의 키로 채워진 이름 형식 옵션을 가질 수 있음.\n",
        "예를 들어 filepath가 weights.{epoch:02d}-{val_loss:.2f}.hdf5라면, 파일 이름에 세대 번호와 검증 손실을 넣어 모델의 체크포인트가 저장 \n",
        "* monitor: 모니터할 지표(loss 또는 평가 지표) \n",
        "* save_best_only: 가장 좋은 성능을 나타내는 모델만 저장할 여부\n",
        "* save_weights_only: Weights만 저장할 지 여부 \n",
        "* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 자동으로 유추. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FNxWnJ3vYl4v"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DVkwmC9iYl4w"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "mcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n",
        "                         save_best_only=True, save_weights_only=True, mode='min', period=3, verbose=1)\n",
        "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=10, validation_data=(val_images, val_oh_labels),\n",
        "                   callbacks=[mcp_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0yvmd74cYl4w"
      },
      "source": [
        "!ls -lia\n",
        "#!rm -rf weight*\n",
        "#!ls -lia\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX0DuUgqYl4x"
      },
      "source": [
        "#### ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "* 특정 epochs 횟수동안 성능이 개선 되지 않을 시 Learning rate를 동적으로 감소 시킴 \n",
        "* monitor: 모니터할 지표(loss 또는 평가 지표) \n",
        "* factor: 학습 속도를 줄일 인수. new_lr = lr * factor \n",
        "* patience: Learing Rate를 줄이기 전에 monitor할 epochs 횟수. \n",
        "* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sTv4GyxSYl4x"
      },
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, mode='min', verbose=1)\n",
        "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels),\n",
        "                   callbacks=[rlr_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKd319tDYl4y"
      },
      "source": [
        "#### EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
        "* 특정 epochs 동안 성능이 개선되지 않을 시 학습을 조기에 중단\n",
        "* monitor: 모니터할 지표(loss 또는 평가 지표) \n",
        "* patience: Early Stopping 적용 전에 monitor할 epochs 횟수. \n",
        "* mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qK3c89wyYl4y"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=3, mode='min', verbose=1)\n",
        "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=30, validation_data=(val_images, val_oh_labels),\n",
        "                   callbacks=[ely_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Mc-wcxgHYl4z"
      },
      "source": [
        "!rm weigh*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0tZGVvnBYl4z"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "model = create_model()\n",
        "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "mcp_cb = ModelCheckpoint(filepath='/kaggle/working/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n",
        "                         save_best_only=True, save_weights_only=True, mode='min', period=1, verbose=0)\n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, mode='min', verbose=1)\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=7, mode='min', verbose=1)\n",
        "\n",
        "history = model.fit(x=tr_images, y=tr_oh_labels, batch_size=128, epochs=40, validation_data=(val_images, val_oh_labels),\n",
        "                   callbacks=[mcp_cb, rlr_cb, ely_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NUjQXV-sYl40"
      },
      "source": [
        "!ls -lia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "98r2TFLMYl40"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}