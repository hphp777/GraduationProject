{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Plant_Pathology.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hphp777/GraduationProject01/blob/main/CVStudy/Fundamental/Plant_Pathology.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pxr8RVs4HuR"
      },
      "source": [
        "### 디렉토리 구조 확인하고 학습과 테스트용 메타 정보를 DataFrame으로 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "4YHItR6m4HuV"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rEFTzkOA4HuW"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "\n",
        "test_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\n",
        "train_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8QdT1RBJ4HuW"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F08u9nu_4HuX"
      },
      "source": [
        "### healthy, multiple_diseases, rust, scab 컬럼이 원핫 인코딩 형식으로 되어 있음. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vvWhPuCH4HuX"
      },
      "source": [
        "# healthy, multiple_diseases, rust, scab 컬럼을 합해서 sum을 만들고 sum이 1보다 큰지, 아니면 0인지 확인. \n",
        "train_df['sum'] = train_df['healthy'] + train_df['multiple_diseases'] + train_df['rust'] + train_df['scab']\n",
        "train_df[(train_df['sum'] > 1) | (train_df['sum']==0)] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Uwamaf14HuY"
      },
      "source": [
        "### 이미지의 절대 경로를 DataFrame에 추가하고, 개별 컬럼별 0/1 값을 구분하여 클래스 라벨로 생성. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fpyqyizs4HuY"
      },
      "source": [
        "pd.set_option(\"max_colwidth\", 100)\n",
        "\n",
        "IMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\n",
        "train_df['path'] = IMAGE_DIR + '/' + train_df['image_id'] + '.jpg'\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iUhOErfV4HuZ"
      },
      "source": [
        "def get_label(x):\n",
        "    if x['healthy'] == 1:\n",
        "        return 'healthy'\n",
        "    elif x['multiple_diseases'] == 1:\n",
        "        return 'multiple_diseases'\n",
        "    elif x['rust'] == 1:\n",
        "        return 'rust'\n",
        "    elif x['scab'] == 1:\n",
        "        return 'scab'\n",
        "    else: return 'None'\n",
        "\n",
        "\n",
        "train_df['label'] = train_df.apply(lambda x:get_label(x), axis=1)\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "p1b9tcD14Hua"
      },
      "source": [
        "## 학습 이미지 건수 및 label별 건수\n",
        "print('train shape:', train_df.shape)\n",
        "print('label 별 건수')\n",
        "train_df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3-xE6L64Hub"
      },
      "source": [
        "### 원본 이미지 시각화\n",
        "* 녹병균 (Rust), 박테리아성 질환(scab), 복합질병(multiple_diseases), 건강(healthy)\n",
        "* 이미지 size는 (1365, 2048)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BzmiWDZj4Huc"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline \n",
        "\n",
        "def show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n",
        "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
        "    for i in range(ncols):\n",
        "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
        "        if augmentor is not None:\n",
        "            image = augmentor(image=image)['image']\n",
        "        axs[i].imshow(image)\n",
        "        #axs[i].axis('off')\n",
        "        axs[i].set_title(title)\n",
        "        print(image.shape)\n",
        "        \n",
        "rust_image_list = train_df[train_df['label']=='rust']['path'].iloc[:6].tolist()\n",
        "scab_image_list = train_df[train_df['label']=='scab']['path'].iloc[:6].tolist()\n",
        "healthy_image_list = train_df[train_df['label']=='healthy']['path'].iloc[:6].tolist()\n",
        "multiple_image_list = train_df[train_df['label']=='multiple_diseases']['path'].iloc[:6].tolist()\n",
        "\n",
        "show_grid_images(rust_image_list, ncols=6, title='rust')\n",
        "show_grid_images(scab_image_list, ncols=6, title='scab')\n",
        "show_grid_images(healthy_image_list, ncols=6, title='healthy')\n",
        "show_grid_images(multiple_image_list, ncols=6, title='multiple')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uukil-uh4Hud"
      },
      "source": [
        "### 이미지 Augmentation 적용. \n",
        "* cutout과 같은 noise는 나뭇잎의 병균 반점과 헷갈릴 수 있으므로 사용하지 않음. \n",
        "* 전체 이미지가 파란색 계열이고 병균 반점이 특정 색깔을 가지고 있으므로 색상의 변화는 적용하지 않음. \n",
        "* 전반적으로 판별하려는 나뭇잎이 전체 이미지의 중앙에 와있음. scale등의 적용 고려. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FpZO9kw_4Hue"
      },
      "source": [
        "import albumentations as A\n",
        "\n",
        "augmentor_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
        "    A.Blur(p=0.2)\n",
        "])\n",
        "\n",
        "show_grid_images(rust_image_list, augmentor=None, ncols=6, title='original rust')\n",
        "show_grid_images(rust_image_list, augmentor=augmentor_01, ncols=6, title='augmented rust')\n",
        "\n",
        "show_grid_images(scab_image_list, augmentor=None, ncols=6, title='original scab')\n",
        "show_grid_images(scab_image_list, augmentor=augmentor_01, ncols=6, title='augmented scab')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cYOgsUc4Hue"
      },
      "source": [
        "### Sequence기반의 Dataset 생성\n",
        "* 기존엔 image size가 높이와 너비가 동일하였으나, 이번엔 높이와 너비가 다를 수 있을 경우를 고려하여 image_size를 튜플로 입력\n",
        "* opencv의 resize()는 인자로 이미지 크기를 입력 받는데 가로x세로(너비x높이)의 개념으로 입력 받음. 이미지 배열의 경우는 행x열(높이x너비) 이므로 resize()호출시 이를 감안할것. \n",
        "* 캐글 컴피티션에 테스트 데이터의 결과를 submit하므로 테스트 데이트의 Label이 없음. 때문에 Dataset의 label_batch 값이 None이 될 수 있는 경우를 감안해서 코드 재수정 필요. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EcqvAm8d4Huf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn \n",
        "import cv2\n",
        "\n",
        "# 입력 인자 image_filenames, labels는 모두 numpy array로 들어옴. image size는 (높이, 너비)로 수정. \n",
        "class Plant_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, image_size=(224, 224), batch_size=64, \n",
        "                 augmentor=None, shuffle=False, pre_func=None):\n",
        "        '''\n",
        "        파라미터 설명\n",
        "        image_filenames: opencv로 image를 로드할 파일의 절대 경로들\n",
        "        labels: 해당 image의 label들\n",
        "        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
        "        augmentor: albumentations 객체\n",
        "        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
        "        '''\n",
        "        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data의 경우 \n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            # 객체 생성시에 한번 데이터를 섞음. \n",
        "            #self.on_epoch_end()\n",
        "            pass\n",
        "    \n",
        "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
        "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
        "    def __len__(self):\n",
        "        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n",
        "        return int(np.ceil(len(self.image_filenames) / self.batch_size))\n",
        "    \n",
        "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n",
        "    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n",
        "    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n",
        "    def __getitem__(self, index):\n",
        "        # index는 몇번째 batch인지를 나타냄. \n",
        "        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져오면 됨\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # label_batch가 None이 될 수 있음. \n",
        "        else: \n",
        "            label_batch = None\n",
        "        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n",
        "        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n",
        "        # image_batch 배열은 float32 로 설정. \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], self.image_size[0], self.image_size[1], 3), dtype='float32')\n",
        "        \n",
        "        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "            #원본 이미지와 다르게 resize 적용. opencv의 resize은 (가로, 세로)의 개념임. 배열은 (높이, 너비)의 개념이므로 이에 주의하여 opencv resize 인자 입력 필요.  \n",
        "            image = cv2.resize(image, (self.image_size[1], self.image_size[0]))\n",
        "            # 만일 preprocessing_input이 pre_func인자로 들어오면 이를 이용하여 scaling 적용. \n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "                \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "    \n",
        "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            # 전체 image 파일의 위치와 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IMdnWdS4Huh"
      },
      "source": [
        "### 학습 데이터용 DataFrame에서 학습용/검증용 이미지 절대 경로와 Label 추출하고 이를 Dataset으로 생성. \n",
        "* 이미 학습용 DataFrame에 'healthy', 'multiple_diseases', 'rust', 'scab' 순으로 원핫 인코딩 되어 있음. \n",
        "* 캐글에서 테스트 데이터 예측한 결과를 'healthy', 'multiple_diseases', 'rust', 'scab' 순서로 제출을 요구하므로 이를 별도로 다시 원-핫 인코딩 해서는 안됨. \n",
        "* Augmentation은 앞에서 생성한 augmentor_01을 적용. pre_func는 xception용 Preprocessing 함수 적용. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TDnPBToy4Huh"
      },
      "source": [
        "sample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n",
        "sample_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LQ0Yc3QX4Hui"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_train_valid(train_df, valid_size=0.2, random_state=2021):\n",
        "    train_path = train_df['path'].values\n",
        "    # 별도의 원핫인코딩을 하지 않고  'healthy', 'multiple_diseases', 'rust', 'scab' 컬럼들을 모두 Numpy array로 변환하는 수준으로 label을 원핫 인코딩 적용. \n",
        "    train_label = train_df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=valid_size, random_state=random_state)\n",
        "    print('tr_path shape:', tr_path.shape, 'tr_label shape:', tr_label.shape, 'val_path shape:', val_path.shape, 'val_label shape:', val_label.shape)\n",
        "    return tr_path, val_path, tr_label, val_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vUzrggW94Hui"
      },
      "source": [
        "from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "\n",
        "# image size는 224x224로 Dataset 생성. \n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "\n",
        "tr_ds = Plant_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=augmentor_01, shuffle=True, pre_func=xcp_preprocess_input)\n",
        "val_ds = Plant_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                      augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n",
        "\n",
        "tr_image_batch, tr_label_batch = next(iter(tr_ds))\n",
        "val_image_batch, val_label_batch = next(iter(val_ds))\n",
        "print(tr_image_batch.shape, val_image_batch.shape, tr_label_batch.shape, val_label_batch.shape)\n",
        "print(tr_image_batch[0], val_image_batch[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZnv6LfY4Huj"
      },
      "source": [
        "### create_model() 함수 생성. \n",
        "* resnet50v2, xception, efficientnetb0~b7 등의 Pretrained 모델을 생성 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7oqjBmc44Huj"
      },
      "source": [
        "from tensorflow.keras.models import Sequential , Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "from tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "from tensorflow.keras.applications import EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def create_model(model_type='efficientnetb0', in_shape=(224, 224, 3), n_classes=4):\n",
        "    input_tensor = Input(shape=in_shape)\n",
        "\n",
        "    if model_type == 'resnet50v2':\n",
        "        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'xception':\n",
        "        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb1':\n",
        "        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb2':\n",
        "        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb3':\n",
        "        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb4':\n",
        "        base_model = tf.keras.applications.EfficientNetB4(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb5':\n",
        "        base_model = tf.keras.applications.EfficientNetB5(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb6':\n",
        "        base_model = tf.keras.applications.EfficientNetB6(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb7':\n",
        "        base_model = tf.keras.applications.EfficientNetB7(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "        \n",
        "    x = base_model.output  \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)    \n",
        "    preds = Dense(units=n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=input_tensor, outputs=preds)\n",
        "    \n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9m7jEde4Huk"
      },
      "source": [
        "### xception 모델을 생성하고 학습 수행. \n",
        "* image size는 224x224로 생성. \n",
        "* Learning Rate Scheduler는 ReduceLROnPlateau로, 초기 Learning Rate는 0.0001로 설정. \n",
        "* epochs는 10회만 설정. \n",
        "* metrics는 ROC-AUC 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M8WZA5vO4Huk"
      },
      "source": [
        "from tensorflow.keras.metrics import AUC\n",
        "\n",
        "xcp_model_01 = create_model(model_type='xception', in_shape=(224, 224, 3))\n",
        "xcp_model_01.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=[AUC()])\n",
        "\n",
        "# 3번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "\n",
        "history = xcp_model_01.fit(tr_ds, epochs=10, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "               validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "               callbacks=([rlr_cb, ely_cb]), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLkix0CY4Hul"
      },
      "source": [
        "### 테스트 데이터로 Plant의 질병을 예측하고 캐글에 제출할 submit csv 파일 만들기\n",
        "* 테스트용 DataFrame에 이미지 경로 추가. \n",
        "* 테스트용 Dataset 생성. label은 테스트 데이터에서 알 수 없으므로 None으로 입력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tBIwOAWE4Hul"
      },
      "source": [
        "sample_df = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n",
        "sample_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "N1ja_N264Hul"
      },
      "source": [
        "IMAGE_DIR = '/kaggle/input/plant-pathology-2020-fgvc7/images'\n",
        "test_df = pd.read_csv(\"../input/plant-pathology-2020-fgvc7/test.csv\")\n",
        "test_df['path'] = IMAGE_DIR + '/' + test_df['image_id'] + '.jpg'\n",
        "\n",
        "test_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AHjVfMI94Hum"
      },
      "source": [
        "# 테스트용 Dataset을 생성하고 이를 이용하여 model의 predict()를 호출하여 이미지 예측 수행. \n",
        "\n",
        "test_path = test_df['path'].values\n",
        "# labels는 None을 입력하고 Dataset 생성. \n",
        "test_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n",
        "#predict()로 예측 수행. \n",
        "preds = xcp_model_01.predict(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cANXqX0s4Hum"
      },
      "source": [
        "preds_df = pd.DataFrame(preds)\n",
        "preds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n",
        "preds_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KvPonI634Hun"
      },
      "source": [
        "# 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성. \n",
        "preds_df = pd.DataFrame(preds)\n",
        "preds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n",
        "# 테스트용 DataFrame에 바로 위에서 생성한 결과 DataFrame을 합친 뒤 이를 이용하여 submit용 DataFrame 생성.  \n",
        "submit_df = pd.concat([test_df['image_id'], preds_df], axis = 1)\n",
        "submit_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSILpN0s4Huq"
      },
      "source": [
        "### 캐글 제출용 CSV 생성 후 캐글에 제출 및 테스트 성능 확인  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ATgpxbPb4Huq"
      },
      "source": [
        "submit_df.to_csv('submit_01.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i6Hy7Aj34Hur"
      },
      "source": [
        "def make_submit_df(test_df, model):\n",
        "    test_path = test_df['path'].values\n",
        "    # labels는 None을 입력하고 Dataset 생성. \n",
        "    test_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                            augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n",
        "    #predict()로 예측 수행. \n",
        "    preds = model.predict(test_ds)\n",
        "    \n",
        "    # 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성.\n",
        "    preds_df = pd.DataFrame(preds)\n",
        "    preds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n",
        "    # 테스트용 DataFrame에 바로 위에서 생성한 결과 DataFrame을 합친 뒤 이를 이용하여 submit용 DataFrame 생성.  \n",
        "    submit_df = pd.concat([test_df['image_id'], preds_df], axis = 1)\n",
        "    \n",
        "    return submit_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3eqYuNSX4Hur"
      },
      "source": [
        "submit_df = make_submit_df(test_df, xcp_model_01)\n",
        "\n",
        "submit_df.to_csv('submit_xcp_01.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNrIwv-b4Hus"
      },
      "source": [
        "### image 사이즈를 변경하여 재 학습 수행. \n",
        "* xception 모델을 사용하되 원본 이미지(1365, 2048)의 ratio를 어느 정도 유지하면서 변경. 이미지 사이즈를 320, 512로 변경. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0mPh-weW4Hus"
      },
      "source": [
        "from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "\n",
        "IMAGE_SIZE = (320, 512)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "\n",
        "tr_ds = Plant_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=augmentor_01, shuffle=True, pre_func=xcp_preprocess_input)\n",
        "val_ds = Plant_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                      augmentor=None, shuffle=False, pre_func=xcp_preprocess_input)\n",
        "\n",
        "tr_image_batch, tr_label_batch = next(iter(tr_ds))\n",
        "val_image_batch, val_label_batch = next(iter(val_ds))\n",
        "print(tr_image_batch.shape, val_image_batch.shape, tr_label_batch.shape, val_label_batch.shape)\n",
        "print(tr_image_batch[0], val_image_batch[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT5t1N-54Hut"
      },
      "source": [
        "### Config 를 이용하여 학습 수행. \n",
        "* 모델은 xception, image size는 (320, 512), \n",
        "* 초기 LR은 0.0001, LR Scheduler는 Ramp up and Step decay, \n",
        "* epochs는 10회, fine tuning을 적용하지 않음.\n",
        "* augmentor는 앞에서 설정한 augmentor_01 적용. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KH8fpfdx4Hut"
      },
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "from tensorflow.keras.applications.xception import preprocess_input as xcp_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# learning rate scheduler에 적용할 함수 선언. \n",
        "def lrfn_01(epoch):\n",
        "    LR_START = 1e-5\n",
        "    LR_MAX = 1e-4\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "def lrfn_02(epoch):\n",
        "    LR_START = 1e-6\n",
        "    LR_MAX = 2e-5\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "# Config에 입력할 callback 생성. \n",
        "lr01_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_01, verbose=1)\n",
        "lr02_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_02, verbose=1)\n",
        "rlr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "\n",
        "ely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "\n",
        "# Augmentor 생성. \n",
        "augmentor_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.5, rotate_limit=30),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5),\n",
        "    A.Blur(p=0.2)\n",
        "])\n",
        "\n",
        "# Config 생성. \n",
        "class Config:\n",
        "    MODEL_TYPE = 'xception'\n",
        "    IMAGE_SIZE = (320, 512)\n",
        "    BATCH_SIZE = 32\n",
        "    N_EPOCHS = 10 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = False\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n",
        "    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = augmentor_01\n",
        "    PRE_FUNC = xcp_preprocess_input\n",
        "    INITIAL_LR = 0.0001\n",
        "    DEBUG = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "W484lVBr4Huu"
      },
      "source": [
        "def train_model(train_df, config=Config):\n",
        "    # 학습과 검증 데이터 이미지/레이블로 분리하고 학습/검증 Dataset 생성. \n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "    \n",
        "    tr_ds = Plant_Dataset(tr_path, tr_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n",
        "    val_ds = Plant_Dataset(val_path, val_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n",
        "    if config.DEBUG:\n",
        "        tr_image_batch = next(iter(tr_ds))[0]\n",
        "        val_image_batch = next(iter(val_ds))[0]\n",
        "        print(tr_image_batch.shape, val_image_batch.shape)\n",
        "        print(tr_image_batch[0], val_image_batch[0])\n",
        "        \n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE[0], config.IMAGE_SIZE[1], 3), n_classes=4)\n",
        "    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=[AUC()])\n",
        "    \n",
        "    # 만일 Fine tuning 일 경우 아래 로직 적용. \n",
        "    if config.IS_FINE_TUNING:\n",
        "        print('####### Fine tuning 학습을 시작합니다. ########')\n",
        "        # 첫번째 Fine Tuning. Feature Extractor를 제외한 classification layer를 학습.(Feature Extractor layer들을 trainable=False 설정)\n",
        "        for layer in model.layers[:-4]:\n",
        "            layer.trainable = False\n",
        "        \n",
        "        print('####### Classification Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.FIRST_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "        # 두번째, 전체 Layer를 학습. 전체 layer를 trainable=True로 수정. 모델이 EfficientNet 계열일 경우 Batch Normalization layer는 학습 제외. \n",
        "        for layer in model.layers:\n",
        "            if config.MODEL_TYPE in 'efficientnet':\n",
        "                if not isinstance(layer, layers.BatchNormalization):\n",
        "                    layer.trainable = True\n",
        "            else:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        print('####### 전체 Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.SECOND_CALLBACKS), verbose=1)\n",
        "    \n",
        "    # Fine Tuning이 아닐 경우 \n",
        "    else:\n",
        "        print('####### 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                       callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8frMPO_y4Huv"
      },
      "source": [
        "xcp_model_02, history = train_model(train_df, config=Config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqlNE_T74Huv"
      },
      "source": [
        "### 학습된 모델을 이용하여 테스트 이미지 예측 및 결과 제출 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gcxHZu0R4Huv"
      },
      "source": [
        "def make_submit_df(test_df, model, config=Config):\n",
        "    test_path = test_df['path'].values\n",
        "    # labels는 None을 입력하고 Dataset 생성. \n",
        "    test_ds = Plant_Dataset(image_filenames=test_path, labels=None, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                            augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n",
        "    #predict()로 예측 수행. \n",
        "    preds = model.predict(test_ds)\n",
        "    \n",
        "    # 예측한 결과를 기반으로 별도의 결과 DataFrame을 생성.\n",
        "    preds_df = pd.DataFrame(preds)\n",
        "    preds_df.columns = ['healthy', 'multiple_diseases', 'rust', 'scab']\n",
        "    # 테스트용 DataFrame에 바로 위에서 생성한 결과 DataFrame을 합친 뒤 이를 이용하여 submit용 DataFrame 생성.  \n",
        "    submit_df = pd.concat([test_df['image_id'], preds_df], axis = 1)\n",
        "    \n",
        "    return submit_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TibQGBo64Huv"
      },
      "source": [
        "submit_df = make_submit_df(test_df, xcp_model_02, config=Config)\n",
        "\n",
        "submit_df.to_csv('submit_xcp_02.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ0oKWnS4Huw"
      },
      "source": [
        "### EfficientNetB3로 Pretrained 모델을 변경한 후 다시 학습 및 테스트 데이터 평가 후 제출. \n",
        "* BATCH_SIZE를 16으로 줄이지 않으면 OOM 오류 발생. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EtQ9CBAq4Huw"
      },
      "source": [
        "# Config 생성. \n",
        "class Config:\n",
        "    MODEL_TYPE = 'efficientnetb3'\n",
        "    IMAGE_SIZE = (320, 512)\n",
        "    BATCH_SIZE = 16\n",
        "    N_EPOCHS = 10 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = False\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n",
        "    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = augmentor_01\n",
        "    PRE_FUNC = eff_preprocess_input\n",
        "    INITIAL_LR = 0.0001\n",
        "    DEBUG = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7WENo2ts4Huw"
      },
      "source": [
        "effb3_model, history = train_model(train_df, config=Config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ApB7oLax4Huw"
      },
      "source": [
        "submit_df = make_submit_df(test_df, effb3_model, config=Config)\n",
        "\n",
        "submit_df.to_csv('submit_effb3.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JphxbzRP4Hux"
      },
      "source": [
        "### EfficientNetB5로 Pretrained 모델을 변경한 후 다시 학습 및 테스트 데이터 평가 후 제출. \n",
        "* IMAGE_SIZE는 (456, 456)으로 증가.  \n",
        "* BATCH_SIZE를 8로 줄이지 않으면 OOM 오류 발생. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bIHD18YJ4Hux"
      },
      "source": [
        "class Config:\n",
        "    MODEL_TYPE = 'efficientnetb5'\n",
        "    IMAGE_SIZE = (456, 456)\n",
        "    BATCH_SIZE = 8\n",
        "    N_EPOCHS = 10 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = False\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n",
        "    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = augmentor_01\n",
        "    PRE_FUNC = eff_preprocess_input\n",
        "    INITIAL_LR = 0.0001\n",
        "    DEBUG = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H_rcGp404Hux"
      },
      "source": [
        "effb5_model, history = train_model(train_df, config=Config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RZ53lQjh4Hux"
      },
      "source": [
        "submit_df = make_submit_df(test_df, effb5_model, config=Config)\n",
        "\n",
        "submit_df.to_csv('submit_effb5.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BguJQgD4Huy"
      },
      "source": [
        "### EfficientNetB7로 Pretrained 모델을 변경한 후 다시 학습 및 테스트 데이터 평가 후 제출. \n",
        "* 기존 검증 데이터를 합쳐서 학습 데이터로 활용. \n",
        "* IMAGE_SIZE는 (456, 456)으로 유지.  \n",
        "* BATCH_SIZE를 4로 줄이지 않으면 OOM 오류 발생. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mDzu3-fF4Huy"
      },
      "source": [
        "class Config:\n",
        "    MODEL_TYPE = 'efficientnetb7'\n",
        "    IMAGE_SIZE = (456, 456)\n",
        "    BATCH_SIZE = 4\n",
        "    N_EPOCHS = 15 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = False\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n",
        "    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = augmentor_01\n",
        "    PRE_FUNC = eff_preprocess_input\n",
        "    INITIAL_LR = 0.0001\n",
        "    DEBUG = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l3kYJxDx4Huy"
      },
      "source": [
        "def train_only_model(train_df, config=Config):\n",
        "    # 학습과 검증 데이터 이미지/레이블로 분리하고 학습/검증 Dataset 생성. \n",
        "    train_path = train_df['path'].values\n",
        "    # 별도의 원핫인코딩을 하지 않고  'healthy', 'multiple_diseases', 'rust', 'scab' 컬럼들을 모두 Numpy array로 변환하는 수준으로 label을 원핫 인코딩 적용. \n",
        "    train_label = train_df[['healthy', 'multiple_diseases', 'rust', 'scab']].values\n",
        "    \n",
        "    tr_ds = Plant_Dataset(train_path, train_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n",
        "    if config.DEBUG:\n",
        "        tr_image_batch = next(iter(tr_ds))[0]\n",
        "        print(tr_image_batch.shape)\n",
        "        print(tr_image_batch[0])\n",
        "        \n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE[0], config.IMAGE_SIZE[1], 3), n_classes=4)\n",
        "    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=[AUC()])\n",
        "    \n",
        "    # 만일 Fine tuning 일 경우 아래 로직 적용. \n",
        "    if config.IS_FINE_TUNING:\n",
        "        print('####### Fine tuning 학습을 시작합니다. ########')\n",
        "        # 첫번째 Fine Tuning. Feature Extractor를 제외한 classification layer를 학습.(Feature Extractor layer들을 trainable=False 설정)\n",
        "        for layer in model.layers[:-4]:\n",
        "            layer.trainable = False\n",
        "        \n",
        "        print('####### Classification Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.FIRST_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           #validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "        # 두번째, 전체 Layer를 학습. 전체 layer를 trainable=True로 수정. 모델이 EfficientNet 계열일 경우 Batch Normalization layer는 학습 제외. \n",
        "        for layer in model.layers:\n",
        "            if config.MODEL_TYPE in 'efficientnet':\n",
        "                if not isinstance(layer, layers.BatchNormalization):\n",
        "                    layer.trainable = True\n",
        "            else:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        print('####### 전체 Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           #validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.SECOND_CALLBACKS), verbose=1)\n",
        "    \n",
        "    # Fine Tuning이 아닐 경우 \n",
        "    else:\n",
        "        print('####### 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                       #validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                       callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lTP7Lu_e4Huz"
      },
      "source": [
        "effb7_model, history = train_only_model(train_df, config=Config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GuVE6mmo4Huz"
      },
      "source": [
        "submit_df = make_submit_df(test_df, effb7_model, config=Config)\n",
        "submit_df.to_csv('submit_effb7.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FDp2YtDs4Hu0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Gg8egSJU4Hu0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}