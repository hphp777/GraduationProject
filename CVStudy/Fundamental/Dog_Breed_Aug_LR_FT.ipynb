{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Dog_Breed_Aug_LR_FT.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hphp777/GraduationProject01/blob/main/CVStudy/Fundamental/Dog_Breed_Aug_LR_FT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX_gWm6gGQ-4"
      },
      "source": [
        "### Stanford Dog Breed 데이터 세트를 아래 URL에서 직접 Download 및 압축 해제\n",
        "* Kaggle의 Dataset으로 Object Storage 연결 시 이미지를 한장 씩 읽는 데 많은 시간이 소요되어 모델 학습에 시간이 더 걸림. \n",
        "* Local Disk에 바로 이미지를 다운로드/압축 해제 후 모델에서 이를 이용할 수 있도록 함. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zaNZ25raGQ-9"
      },
      "source": [
        "# stanford dog breed 데이터 세트 다운로드 \n",
        "!wget http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\n",
        "# 현재 디렉토리인 /kaggle/working에 바로 압축 해제 \n",
        "!ls; tar -xvf images.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQplkh22GQ-_"
      },
      "source": [
        "### Pretrained 모델 생성. \n",
        "* resnet50, xception, efficientnetb0, efficientnetb1 등으로 pretrained 모델을 생성할 수 있는 함수 생성. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xVR44cPlGQ-_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential , Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "import tensorflow as tf\n",
        "\n",
        "# dog breed 종류는 120가지\n",
        "\n",
        "def create_model(model_type='xception', in_shape=(224, 224, 3), n_classes=120):\n",
        "    input_tensor = Input(shape=in_shape)\n",
        "    if model_type == 'resnet50v2':\n",
        "        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'xception':\n",
        "        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb1':\n",
        "        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "        \n",
        "    x = base_model.output  \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)    \n",
        "    preds = Dense(units=n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=input_tensor, outputs=preds)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ2cdKsWGQ_A"
      },
      "source": [
        "### 학습/검증 데이터 분할, Dataset 생성, 모델 생성, 모델 Opt, Loss설정, Learning Rate Callback 설정 함수 생성. \n",
        "* Prtrained 모델 유형, 메타 DataFrame, 초기 학습율, Augmentor, scaling 함수를 인자로 입력. \n",
        "* Learning Rate Scheduler는 ReduceLROnPlateau 적용. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GiDGoGh9GQ_B"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn \n",
        "import cv2\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "IMAGE_DIR = '/kaggle/working/Images'\n",
        "\n",
        "def make_dogbreed_dataframe(image_dir=IMAGE_DIR):\n",
        "    paths = []\n",
        "    label_gubuns = []\n",
        "    for dirname, _, filenames in os.walk(image_dir):\n",
        "        for filename in filenames:\n",
        "            # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n",
        "            if '.jpg' in filename:\n",
        "                # 파일의 절대 경로를 file_path 변수에 할당. \n",
        "                file_path = dirname+'/'+ filename\n",
        "                paths.append(file_path)\n",
        "                # 이미지 파일의 절대 경로에서 레이블명 생성을 위한 1차 추출. '/'로 분할하여 파일 바로 위 서브디렉토리 이름 가져옴.  \n",
        "                start_pos = file_path.find('/', 20)\n",
        "                end_pos = file_path.rfind('/')\n",
        "                imsi_breed = file_path[start_pos+1:end_pos]\n",
        "                # 1차 추출된 데이터를 기반으로 '-' 이후 데이터가 레이블 값임. \n",
        "                breed = imsi_breed[imsi_breed.find('-')+1:]\n",
        "                #print(start_pos, end_pos, imsi_breed)\n",
        "                label_gubuns.append(breed)\n",
        "\n",
        "    data_df = pd.DataFrame({'path':paths, 'label':label_gubuns})\n",
        "    return data_df\n",
        "\n",
        "# 학습과 검증 데이터용 numpy array 분리. \n",
        "def get_train_valid(train_df, valid_size=0.2, random_state=2021):\n",
        "    train_path = train_df['path'].values\n",
        "    train_label = pd.get_dummies(train_df['label']).values\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=valid_size, random_state=random_state)\n",
        "    print('tr_path shape:', tr_path.shape, 'tr_label shape:', tr_label.shape, 'val_path shape:', val_path.shape, 'val_label shape:', val_label.shape)\n",
        "    return tr_path, val_path, tr_label, val_label\n",
        "\n",
        "\n",
        "# 입력 인자 image_filenames, labels는 모두 numpy array로 들어옴. \n",
        "class Breed_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, image_size=224, batch_size=64, \n",
        "                 augmentor=None, shuffle=False, pre_func=None):\n",
        "        '''\n",
        "        파라미터 설명\n",
        "        image_filenames: opencv로 image를 로드할 파일의 절대 경로들\n",
        "        labels: 해당 image의 label들\n",
        "        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
        "        augmentor: albumentations 객체\n",
        "        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
        "        '''\n",
        "        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data의 경우 \n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            # 객체 생성시에 한번 데이터를 섞음. \n",
        "            #self.on_epoch_end()\n",
        "            pass\n",
        "    \n",
        "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
        "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
        "    def __len__(self):\n",
        "        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "    \n",
        "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n",
        "    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n",
        "    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n",
        "    def __getitem__(self, index):\n",
        "        # index는 몇번째 batch인지를 나타냄. \n",
        "        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져오면 됨\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n",
        "        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n",
        "        # image_batch 배열은 float32 로 설정. \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], self.image_size, self.image_size, 3), dtype='float32')\n",
        "        \n",
        "        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "            #crop 시 잘린 이미지가 원본 이미지와 다르게 되므로 augmentation 적용 후 resize() 적용. \n",
        "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "            # 만일 preprocessing_input이 pre_func인자로 들어오면 이를 이용하여 scaling 적용. \n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "                \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "    \n",
        "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            # 전체 image 파일의 위치와 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass\n",
        "        \n",
        "        \n",
        "augmentor_light = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "])\n",
        "\n",
        "IMAGE_DIR = '/kaggle/working/Images' \n",
        "\n",
        "data_df = make_dogbreed_dataframe(image_dir=IMAGE_DIR)\n",
        "train_df, test_df = train_test_split(data_df, test_size=0.4, stratify=data_df['label'], random_state=2021)\n",
        "print(train_df.shape, test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XPL8fab1GQ_E"
      },
      "source": [
        "N_EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "def train_model(model_type, train_df, initial_lr=0.001, augmentor=None, input_pre_func=None):\n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "    \n",
        "    tr_ds = Breed_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=augmentor, shuffle=True, pre_func=input_pre_func)\n",
        "    val_ds = Breed_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=input_pre_func)\n",
        "    print('### train dataset shape:', next(iter(tr_ds))[0].shape)\n",
        "\n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', model_type, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=model_type)\n",
        "    model.compile(optimizer=Adam(lr=initial_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 3번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n",
        "    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n",
        "    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "    \n",
        "    history = model.fit(tr_ds, epochs=N_EPOCHS, steps_per_epoch=tr_path.shape[0]//BATCH_SIZE, \n",
        "                   validation_data=val_ds, validation_steps=val_path.shape[0]//BATCH_SIZE,\n",
        "                   callbacks=([rlr_cb, ely_cb]), verbose=1)\n",
        "    \n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6RdatyusGQ_F"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "\n",
        "def show_grid_images(image_path_list, augmentor=None, ncols=4, title=None):\n",
        "    figure, axs = plt.subplots(figsize=(22, 4), nrows=1, ncols=ncols)\n",
        "    for i in range(ncols):\n",
        "        image = cv2.cvtColor(cv2.imread(image_path_list[i]), cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        if augmentor is not None:\n",
        "            image = augmentor(image=image)['image']\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].axis('off')\n",
        "        axs[i].set_title(title) \n",
        "        \n",
        "breed_image_list_01 = data_df[data_df['label']=='Siberian_husky']['path'].iloc[:6].tolist()\n",
        "breed_image_list_02 = data_df[data_df['label']=='Eskimo_dog']['path'].iloc[:6].tolist()\n",
        "\n",
        "show_grid_images(breed_image_list_01, ncols=6, title='Siberian_husky')\n",
        "show_grid_images(breed_image_list_02, ncols=6, title='Eskimo_dog')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPa4gNw4GQ_G"
      },
      "source": [
        "### EfficientNetB0 기반에서 Augmentation 기법을 변화 시키면서 모델 학습. ReduceLROnPlateau 적용. \n",
        "* 학습 데이터가 적을 경우 Augmentation이 너무 약할 경우, 과적합(Overfitting), Augmentation이 너무 강하거나 잘못 될 경우 과소적합(Underfitting)이 가능성이 있음. \n",
        "* 이전에 적용한 좌우 반전보다는 더 다양한 기법을 적용하면서 모델 학습하고, 학습데이터와 검증 데이터의 loss/metric 변화 추이 모니터링. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "n_3sS1IFGQ_G"
      },
      "source": [
        "augmentor_heavy_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.2),\n",
        "    A.CenterCrop(height=90, width=90, p=0.2),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=1, max_holes=26), \n",
        "         A.CLAHE(p=1),\n",
        "         A.Blur(blur_limit=(10, 15), p=1)\n",
        "        ], p=0.3)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "do91XskaGQ_H"
      },
      "source": [
        "breed_image_list_01 = data_df[data_df['label']=='Staffordshire_bullterrier']['path'].iloc[:6].tolist()       \n",
        "show_grid_images(breed_image_list_01, augmentor=None, ncols=6, title='orignal Staffordshire_bullterrier')\n",
        "show_grid_images(breed_image_list_01, augmentor=augmentor_heavy_01, ncols=6, title='augmented')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ic3heDtuGQ_J"
      },
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "\n",
        "effb0_model_aug01, effb0_history_aug01 = train_model(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                                     augmentor=augmentor_heavy_01, input_pre_func=eff_preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0WYamefGQ_J"
      },
      "source": [
        "### 학습된 모델을 이용하여 테스트 데이터로 Evaluation 및 Prediction 수행. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y5RjSOodGQ_K"
      },
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "test_classes = np.argmax(test_label, axis=1)\n",
        "test_df['gt_class'] = test_classes\n",
        "\n",
        "test_ds = Breed_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_aug01.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R2tctf9sGQ_K"
      },
      "source": [
        "# 테스트 Dataset으로 개별 image들의 predict 수행. \n",
        "predict_result = effb0_model_aug01.predict(test_ds, steps=int(np.ceil(len(test_label)/BATCH_SIZE)))\n",
        "predict_class = np.argmax(predict_result, axis=1)\n",
        "\n",
        "test_df['effb0_aug01_pred_class'] = predict_class\n",
        "print(test_df[test_df['gt_class'] != test_df['effb0_aug01_pred_class']]['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5YpfwYQGQ_L"
      },
      "source": [
        "### 다른 Augmentation을 적용. \n",
        "* CenterCrop 제외하고 probability를 약간 변경.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "drLp7wQ-GQ_L"
      },
      "source": [
        "augmentor_heavy_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.3),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
        "    A.ColorJitter(p=0.3),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=0.3, max_holes=26), \n",
        "         A.CLAHE(p=0.3),\n",
        "         A.Blur(blur_limit=(10, 15), p=0.3)\n",
        "        ], p=0.3)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vYSxY0swGQ_M"
      },
      "source": [
        "breed_image_list_01 = data_df[data_df['label']=='Staffordshire_bullterrier']['path'].iloc[:6].tolist()       \n",
        "show_grid_images(breed_image_list_01, augmentor=None, ncols=6, title='orignal Staffordshire_bullterrier')\n",
        "show_grid_images(breed_image_list_01, augmentor=augmentor_heavy_02, ncols=6, title='augmented Staffordshire_bullterrier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SGgh72YSGQ_M"
      },
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "\n",
        "effb0_model_aug02, effb0_history_aug02 = train_model(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001,\n",
        "                                               augmentor=augmentor_heavy_02, input_pre_func=eff_preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QfX-8Y3XGQ_M"
      },
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "\n",
        "\n",
        "test_ds = Breed_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_aug02.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6LSUj6SGQ_N"
      },
      "source": [
        "### Learning Rate Scheduler를 Ramp Up and Step Decay 방식으로 변경\n",
        "* 최초는 1e-5에서 2회 Ramp up 단계를 거쳐서, Max인 1e-4까지 증가 시킴. 이후는 Step Decay 방식으로 2회 마다 learning rate를 줄임. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FHQiSKuGGQ_N"
      },
      "source": [
        "# learning rate scheduler에 적용할 함수 선언. 내포 함수를 사용. \n",
        "def lrfn(epoch):\n",
        "    # 내포 함수인 calc_fn()에서 사용되는 파라미터. \n",
        "    LR_START = 1e-5\n",
        "    LR_MAX = 1e-4\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 2\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    # 반드시 내포 함수인 calc_fn(epoch)를 호출해야함. \n",
        "    return calc_fn(epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LTtxhBW0GQ_N"
      },
      "source": [
        "for i in range(30):\n",
        "    print(lrfn(i+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-EhpymX3GQ_N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-FAvw1lGQ_N"
      },
      "source": [
        "### 기존 train_model()에 RampUp and Step Decay를 Callback으로 반영할 수 있도록 train_model_with_aug_lr()로 함수 수정.\n",
        "* Learning Rate Scheduler등의 Callback 객체를 인자로 입력 받을 수 있도록 함수 수정. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sKVpWP0cGQ_O"
      },
      "source": [
        "N_EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "def train_model_with_aug_lr(model_type, train_df, initial_lr=0.001, augmentor=None, callbacks_list=None, input_pre_func=None):\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "    \n",
        "    tr_ds = Breed_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=augmentor, shuffle=True, pre_func=input_pre_func)\n",
        "    val_ds = Breed_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=input_pre_func)\n",
        "\n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', model_type, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=model_type)\n",
        "    model.compile(optimizer=Adam(lr=initial_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # learning rate scheduler와 early stopping 을 함수 인자로 입력 받음. \n",
        "    history = model.fit(tr_ds, epochs=N_EPOCHS, steps_per_epoch=tr_path.shape[0]//BATCH_SIZE, \n",
        "                   validation_data=val_ds, validation_steps=val_path.shape[0]//BATCH_SIZE,\n",
        "                   callbacks=(callbacks_list), verbose=1)\n",
        "    \n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4vs_UK1kGQ_O"
      },
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# Learning Rate Scheduler(Ramp up and step down decay) 와 Early Stopping callback 생성. \n",
        "lr_cb = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
        "ely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "# train_model에 인자로 넣을 Callback 객체의 리스트 생성. \n",
        "callbacks_list = [lr_cb, ely_cb]\n",
        "\n",
        "augmentor_heavy_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.2),\n",
        "    A.CenterCrop(height=90, width=90, p=0.2),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=1, max_holes=26), \n",
        "         A.CLAHE(p=1),\n",
        "         A.Blur(blur_limit=(10, 15), p=1)\n",
        "        ], p=0.3)\n",
        "])\n",
        "\n",
        "augmentor_heavy_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.3),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
        "    A.ColorJitter(p=0.3),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=0.3, max_holes=26), \n",
        "         A.CLAHE(p=0.3),\n",
        "         A.Blur(blur_limit=(10, 15), p=0.3)\n",
        "        ], p=0.3)\n",
        "])\n",
        "\n",
        "# augmentor_heavy_01을 ramp up and step decay 적용. \n",
        "effb0_model_lr01, effb0_history_lr01 = train_model_with_aug_lr(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                               augmentor=augmentor_heavy_01, callbacks_list=callbacks_list, input_pre_func=eff_preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qeQTSApYGQ_P"
      },
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "\n",
        "test_ds = Breed_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_lr01.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mWO0Cft8GQ_P"
      },
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# augmentor_heavy_02를 ramp up and step decay 적용. \n",
        "effb0_model_lr02, effb0_history_lr02 = train_model_with_aug_lr(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                               augmentor=augmentor_heavy_02, callbacks_list=callbacks_list, input_pre_func=eff_preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "302v8667GQ_P"
      },
      "source": [
        "test_ds = Breed_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_lr02.evaluate(test_ds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p5uIV8NGQ_Q"
      },
      "source": [
        "### Pretrained 모델의 Fine Tuning 적용. \n",
        "* Fine tuning으로 1차 dense layer 부터 학습 적용, 2차 전체 Layer 학습 적용. \n",
        "* EfficientNet의 경우는 Batch Normalization은 학습하지 않도록 설정. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Pj6Qs1swGQ_Q"
      },
      "source": [
        "model_imsi =create_model(model_type='efficientnetb0')\n",
        "model_imsi.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6w8RpoHDGQ_Q"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "N_EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "def train_model_with_ft(model_type, train_df, initial_lr=0.0001, augmentor=None, callbacks_list=None, input_pre_func=None):\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "\n",
        "    tr_ds = Breed_Dataset(tr_path, tr_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=augmentor, shuffle=True, pre_func=input_pre_func)\n",
        "    val_ds = Breed_Dataset(val_path, val_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=input_pre_func)\n",
        "\n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', model_type, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=model_type)\n",
        "    \n",
        "    # Feature Extractor layer들을 모두 Freeze\n",
        "    for layer in model.layers[:-4]:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    model.compile(optimizer=Adam(lr=initial_lr), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    #10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n",
        "    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "    #cosine_decay = tf.keras.experimental.CosineDecay(initial_learning_rate=0.001, decay_steps=300)\n",
        "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
        "    \n",
        "    ### Feature Extractor layer들은 학습하지 않고 Dense Layer만 일차 학습. \n",
        "    print('##### Feature Extractor freeze후 Dense layer 학습 시작 ##### ')\n",
        "    history = model.fit(tr_ds, epochs=15, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                  validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                  callbacks=(callbacks_list), verbose=1)\n",
        "    # efficientNet의 일부만 trainable 가능하게 설정. 특히 BatchNormalization layer는 trainable False로 유지. \n",
        "    # https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/\n",
        "    #for layer in model.layers[-20:]:\n",
        "    for layer in model.layers:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "    \n",
        "    print('##### 전체 Layer Unfreeze 후 학습 시작 ##### ')\n",
        "    history = model.fit(tr_ds, epochs=25, steps_per_epoch=int(np.ceil(tr_path.shape[0]/BATCH_SIZE)), \n",
        "                  validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/BATCH_SIZE)),\n",
        "                  callbacks=(callbacks_list), verbose=1)\n",
        "\n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tPRW9kpxGQ_R"
      },
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# learning rate scheduler에 적용할 함수 선언. 내포 함수를 사용. \n",
        "def lrfn(epoch):\n",
        "    # 내포 함수인 calc_fn()에서 사용되는 파라미터. \n",
        "    LR_START = 1e-5\n",
        "    LR_MAX = 1e-4\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    # 반드시 내포 함수인 calc_fn(epoch)를 호출해야함. \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "# Learning Rate Scheduler(Ramp up and step down decay) 와 Early Stopping callback 생성. \n",
        "lr_cb = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
        "ely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "# train_model에 인자로 넣을 Callback 객체의 리스트 생성. \n",
        "callbacks_list = [lr_cb, ely_cb]\n",
        "\n",
        "\n",
        "augmentor_light_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "])\n",
        "\n",
        "augmentor_light_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.2, rotate_limit=30),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2)\n",
        "])\n",
        "\n",
        "augmentor_heavy_01 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.2),\n",
        "    A.CenterCrop(height=90, width=90, p=0.2),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=1, max_holes=26), \n",
        "         A.CLAHE(p=1),\n",
        "         A.Blur(blur_limit=(10, 15), p=1)\n",
        "        ], p=0.3)\n",
        "])\n",
        "\n",
        "augmentor_heavy_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(p=0.3),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.3),\n",
        "    A.ColorJitter(p=0.3),\n",
        "    A.OneOf(\n",
        "        [A.CoarseDropout(p=0.3, max_holes=26), \n",
        "         A.CLAHE(p=0.3),\n",
        "         A.Blur(blur_limit=(10, 15), p=0.3)\n",
        "        ], p=0.3)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "joAEJ5eoGQ_R"
      },
      "source": [
        "effb0_model_ft01, effb0_history_ft01 = train_model_with_ft(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                            augmentor=augmentor_heavy_01, callbacks_list=callbacks_list, input_pre_func=eff_preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fupbJDobGQ_R"
      },
      "source": [
        "test_path = test_df['path'].values\n",
        "test_label = pd.get_dummies(test_df['label']).values\n",
        "\n",
        "test_ds = Breed_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_ft01.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOtierTaGQ_R"
      },
      "source": [
        "### lighter한 Augmentation 적용. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CzdIfs-NGQ_S"
      },
      "source": [
        "effb0_model_ft02, effb0_history_ft02 = train_model_with_ft(model_type='efficientnetb0', train_df=train_df, initial_lr=0.0001, \n",
        "                                            augmentor=augmentor_light_02, callbacks_list=callbacks_list, input_pre_func=eff_preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LW7FlbJmGQ_S"
      },
      "source": [
        "test_ds = Breed_Dataset(test_path, test_label, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=eff_preprocess_input)\n",
        "\n",
        "effb0_model_ft02.evaluate(test_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efTwFLL7GQ_T"
      },
      "source": [
        "### 지금까지 변경 테스트한 여러 환경들을 손쉽게 테스트 해볼 수 있도록 함수 재구성. \n",
        "* Config 클래스를 만들어서 여기에 테스트에 필요한 인자들을 모두 설정 할 수 있도록 함. \n",
        "* train_model() 인자로 Config 를 입력 받아서 이를 기반으로 학습을 수행할 수 있도록 변경. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NEwy4mOjGQ_T"
      },
      "source": [
        "class Config:\n",
        "    MODEL_TYPE = 'effcientnetb0'\n",
        "    IMAGE_SIZE = 224\n",
        "    BATCH_SIZE = 64\n",
        "    N_EPOCHS = 30 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = False # Fine Tuning 여부\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 25 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = None # 모델 train시 적용될 callback 객체들의 List\n",
        "    SECOND_CALLBACKS = None # 만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = None\n",
        "    PRE_FUNC = None\n",
        "    INITIAL_LR = 0.0001 # Optimizer에 적용될 최초 Learning rate\n",
        "    DEBUG = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOKLlmYIGQ_T"
      },
      "source": [
        "### 아래는 기존에 사용한 라이브러리 함수를 그대로 가져온 것임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XOMgIpQvGQ_U"
      },
      "source": [
        "from tensorflow.keras.models import Sequential , Model\n",
        "from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam , RMSprop \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n",
        "\n",
        "from tensorflow.keras.applications import Xception, ResNet50V2, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "import tensorflow as tf\n",
        "\n",
        "# dog breed 종류는 120가지\n",
        "N_CLASSES = 120\n",
        "\n",
        "def create_model(model_type='xception', in_shape=(224, 224, 3), n_classes=120):\n",
        "    input_tensor = Input(shape=in_shape)\n",
        "\n",
        "    if model_type == 'resnet50v2':\n",
        "        base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'xception':\n",
        "        base_model = tf.keras.applications.Xception(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb0':\n",
        "        base_model = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb1':\n",
        "        base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb2':\n",
        "        base_model = tf.keras.applications.EfficientNetB2(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "    elif model_type == 'efficientnetb3':\n",
        "        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
        "        \n",
        "    x = base_model.output  \n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)    \n",
        "    preds = Dense(units=n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=input_tensor, outputs=preds)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LtD36cu5GQ_U"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import sklearn \n",
        "import cv2\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "IMAGE_DIR = '/kaggle/working/Images'\n",
        "\n",
        "def make_dogbreed_dataframe(image_dir=IMAGE_DIR):\n",
        "    paths = []\n",
        "    label_gubuns = []\n",
        "    for dirname, _, filenames in os.walk(image_dir):\n",
        "        for filename in filenames:\n",
        "            # 이미지 파일이 아닌 파일도 해당 디렉토리에 있음.\n",
        "            if '.jpg' in filename:\n",
        "                # 파일의 절대 경로를 file_path 변수에 할당. \n",
        "                file_path = dirname+'/'+ filename\n",
        "                paths.append(file_path)\n",
        "                # 이미지 파일의 절대 경로에서 레이블명 생성을 위한 1차 추출. '/'로 분할하여 파일 바로 위 서브디렉토리 이름 가져옴.  \n",
        "                start_pos = file_path.find('/', 20)\n",
        "                end_pos = file_path.rfind('/')\n",
        "                imsi_breed = file_path[start_pos+1:end_pos]\n",
        "                # 1차 추출된 데이터를 기반으로 '-' 이후 데이터가 레이블 값임. \n",
        "                breed = imsi_breed[imsi_breed.find('-')+1:]\n",
        "                #print(start_pos, end_pos, imsi_breed)\n",
        "                label_gubuns.append(breed)\n",
        "\n",
        "    data_df = pd.DataFrame({'path':paths, 'label':label_gubuns})\n",
        "    return data_df\n",
        "\n",
        "# 학습과 검증 데이터용 numpy array 분리. \n",
        "def get_train_valid(train_df, valid_size=0.2, random_state=2021):\n",
        "    train_path = train_df['path'].values\n",
        "    train_label = pd.get_dummies(train_df['label']).values\n",
        "    \n",
        "    tr_path, val_path, tr_label, val_label = train_test_split(train_path, train_label, test_size=valid_size, random_state=random_state)\n",
        "    print('tr_path shape:', tr_path.shape, 'tr_label shape:', tr_label.shape, 'val_path shape:', val_path.shape, 'val_label shape:', val_label.shape)\n",
        "    return tr_path, val_path, tr_label, val_label\n",
        "\n",
        "\n",
        "# 입력 인자 image_filenames, labels는 모두 numpy array로 들어옴. \n",
        "class Breed_Dataset(Sequence):\n",
        "    def __init__(self, image_filenames, labels, image_size=224, batch_size=64, \n",
        "                 augmentor=None, shuffle=False, pre_func=None):\n",
        "        '''\n",
        "        파라미터 설명\n",
        "        image_filenames: opencv로 image를 로드할 파일의 절대 경로들\n",
        "        labels: 해당 image의 label들\n",
        "        batch_size: __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n",
        "        augmentor: albumentations 객체\n",
        "        shuffle: 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n",
        "        '''\n",
        "        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n",
        "        self.image_filenames = image_filenames\n",
        "        self.labels = labels\n",
        "        self.image_size = image_size\n",
        "        self.batch_size = batch_size\n",
        "        self.augmentor = augmentor\n",
        "        self.pre_func = pre_func\n",
        "        # train data의 경우 \n",
        "        self.shuffle = shuffle\n",
        "        if self.shuffle:\n",
        "            # 객체 생성시에 한번 데이터를 섞음. \n",
        "            #self.on_epoch_end()\n",
        "            pass\n",
        "    \n",
        "    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n",
        "    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n",
        "    def __len__(self):\n",
        "        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n",
        "        return int(np.ceil(len(self.labels) / self.batch_size))\n",
        "    \n",
        "    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환한 뒤 다시 반환함\n",
        "    # 인자로 몇번째 batch 인지를 나타내는 index를 입력하면 해당 순서에 해당하는 batch_size 만큼의 데이타를 가공하여 반환\n",
        "    # batch_size 갯수만큼 변환된 image_array와 label_array 반환. \n",
        "    def __getitem__(self, index):\n",
        "        # index는 몇번째 batch인지를 나타냄. \n",
        "        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size:(index+1)*self.batch_size 만큼의 연속 데이터를 가져오면 됨\n",
        "        image_name_batch = self.image_filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        if self.labels is not None:\n",
        "            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        # 만일 객체 생성 인자로 albumentation으로 만든 augmentor가 주어진다면 아래와 같이 augmentor를 이용하여 image 변환\n",
        "        # albumentations은 개별 image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행. \n",
        "        # image_batch 배열은 float32 로 설정. \n",
        "        image_batch = np.zeros((image_name_batch.shape[0], self.image_size, self.image_size, 3), dtype='float32')\n",
        "        \n",
        "        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환(augmentor가 not None일 경우)-> image_batch에 담음. \n",
        "        for image_index in range(image_name_batch.shape[0]):\n",
        "            image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n",
        "            if self.augmentor is not None:\n",
        "                image = self.augmentor(image=image)['image']\n",
        "            #crop 시 잘린 이미지가 원본 이미지와 다르게 되므로 augmentation 적용 후 resize() 적용. \n",
        "            image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "            # 만일 preprocessing_input이 pre_func인자로 들어오면 이를 이용하여 scaling 적용. \n",
        "            if self.pre_func is not None:\n",
        "                image = self.pre_func(image)\n",
        "                \n",
        "            image_batch[image_index] = image\n",
        "        \n",
        "        return image_batch, label_batch\n",
        "    \n",
        "    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n",
        "    def on_epoch_end(self):\n",
        "        if(self.shuffle):\n",
        "            #print('epoch end')\n",
        "            # 전체 image 파일의 위치와 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n",
        "            self.image_filenames, self.labels = sklearn.utils.shuffle(self.image_filenames, self.labels)\n",
        "        else:\n",
        "            pass\n",
        "        \n",
        "        \n",
        "augmentor_light = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-SeIlpwGQ_V"
      },
      "source": [
        "### train_model 함수를 Config 클래스 값을 인자로 입력 받을 수 있도록 변경. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZlJuHIMiGQ_V"
      },
      "source": [
        "def train_model(train_df, config=Config):\n",
        "    # 학습과 검증 데이터 이미지/레이블로 분리하고 학습/검증 Dataset 생성. \n",
        "    tr_path, val_path, tr_label, val_label = get_train_valid(train_df, valid_size=0.2, random_state=2021)\n",
        "    \n",
        "    tr_ds = Breed_Dataset(tr_path, tr_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=config.AUGMENTOR, shuffle=True, pre_func=config.PRE_FUNC)\n",
        "    val_ds = Breed_Dataset(val_path, val_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                          augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n",
        "    if config.DEBUG:\n",
        "        tr_image_batch = next(iter(tr_ds))[0]\n",
        "        val_image_batch = next(iter(val_ds))[0]\n",
        "        print(tr_image_batch.shape, val_image_batch.shape)\n",
        "        print(tr_image_batch[0], val_image_batch[0])\n",
        "        \n",
        "    # model_type인자로 들어온 모델 생성. optimizer Adam적용. \n",
        "    print('#######', config.MODEL_TYPE, ' 생성 및 학습 수행 ########')\n",
        "    model = create_model(model_type=config.MODEL_TYPE, in_shape=(config.IMAGE_SIZE, config.IMAGE_SIZE, 3), n_classes=120)\n",
        "    model.compile(optimizer=Adam(lr=config.INITIAL_LR), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    # 만일 Fine tuning 일 경우 아래 로직 적용. \n",
        "    if config.IS_FINE_TUNING:\n",
        "        print('####### Fine tuning 학습을 시작합니다. ########')\n",
        "        # 첫번째 Fine Tuning. Feature Extractor를 제외한 classification layer를 학습.(Feature Extractor layer들을 trainable=False 설정)\n",
        "        for layer in model.layers[:-4]:\n",
        "            layer.trainable = False\n",
        "        \n",
        "        print('####### Classification Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.FIRST_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "        # 두번째, 전체 Layer를 학습. 전체 layer를 trainable=True로 수정. Batch Normalization layer는 fine tuning시 계속 trainable=False 설정. \n",
        "        for layer in model.layers:\n",
        "            if not isinstance(layer, layers.BatchNormalization):\n",
        "                layer.trainable = True\n",
        "        \n",
        "        print('####### 전체 Layer들의 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.SECOND_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                           validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                           callbacks=(config.SECOND_CALLBACKS), verbose=1)\n",
        "    \n",
        "    # Fine Tuning이 아닐 경우 \n",
        "    else:\n",
        "        print('####### 학습을 시작합니다. ########')\n",
        "        history = model.fit(tr_ds, epochs=config.N_EPOCHS, steps_per_epoch=int(np.ceil(tr_path.shape[0]/config.BATCH_SIZE)), \n",
        "                       validation_data=val_ds, validation_steps=int(np.ceil(val_path.shape[0]/config.BATCH_SIZE)),\n",
        "                       callbacks=(config.FIRST_CALLBACKS), verbose=1)\n",
        "        \n",
        "    return model, history\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkuQTi5MGQ_V"
      },
      "source": [
        "### EfficientNetB1 모델 학습 및 성능 평가\n",
        "* Config 클래스의 내부 변수값으로 할당 될 수 있도록 Learning Rate Scheduler에 적용될 함수, Callback 객체, Augmentation객체들을 생성\n",
        "* EfficientNetB1의 경우 240x240 이미지 크기로 최적화 되었으므로 이에 맞게 Config 값 설정. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pDpY9D9zGQ_V"
      },
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess_input\n",
        "import tensorflow as tf\n",
        "\n",
        "# learning rate scheduler에 적용할 함수 선언. \n",
        "def lrfn_01(epoch):\n",
        "    LR_START = 1e-5\n",
        "    LR_MAX = 1e-4\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "def lrfn_02(epoch):\n",
        "    LR_START = 1e-6\n",
        "    LR_MAX = 2e-5\n",
        "    LR_RAMPUP_EPOCHS = 2\n",
        "    LR_SUSTAIN_EPOCHS = 1\n",
        "    LR_STEP_DECAY = 0.75\n",
        "    \n",
        "    def calc_fn(epoch):\n",
        "        if epoch < LR_RAMPUP_EPOCHS:\n",
        "            lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "        elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "            lr = LR_MAX\n",
        "        else:\n",
        "            lr = LR_MAX * LR_STEP_DECAY**((epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)//2)\n",
        "        return lr\n",
        "    \n",
        "    return calc_fn(epoch)\n",
        "\n",
        "# Config에 입력할 callback 생성. \n",
        "lr01_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_01, verbose=1)\n",
        "lr02_cb = tf.keras.callbacks.LearningRateScheduler(lrfn_02, verbose=1)\n",
        "ely_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n",
        "\n",
        "# Augmentor 생성. \n",
        "\n",
        "augmentor_light_02 = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(scale_limit=(0.7, 0.9), p=0.2, rotate_limit=30),\n",
        "    A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.2),\n",
        "    A.ColorJitter(p=0.2)\n",
        "])\n",
        "\n",
        "# Config 생성. \n",
        "class Config:\n",
        "    MODEL_TYPE = 'efficientnetb1'\n",
        "    IMAGE_SIZE = 240\n",
        "    BATCH_SIZE = 64\n",
        "    N_EPOCHS = 30 # fine tuning이 아닐 경우 전체 수행 epoch 횟수\n",
        "    IS_FINE_TUNING = True\n",
        "    FIRST_EPOCHS = 15 # fine tuning 일 경우 첫번째 epoch 횟수\n",
        "    SECOND_EPOCHS = 15 # fine tuning 일 경우 두번째 epoch 횟수\n",
        "    FIRST_CALLBACKS = [lr01_cb, ely_cb] #모델 train시 적용될 callback 객체 리스트\n",
        "    SECOND_CALLBACKS = [lr02_cb, ely_cb] #만일 Fine tuning 시 첫번째 학습과 두번째 학습의 Learning rate scheduler가 서로 다를 경우 사용. \n",
        "    AUGMENTOR = augmentor_light_02\n",
        "    PRE_FUNC = eff_preprocess_input\n",
        "    INITIAL_LR = 0.0001\n",
        "    DEBUG = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KCnP-dvmGQ_W"
      },
      "source": [
        "# EfficientNetB1 모델 학습. \n",
        "eff1_model, history = train_model(train_df, config=Config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "k1zMXenjGQ_W"
      },
      "source": [
        "def evaluate_model(model, test_df, config=Config):\n",
        "    test_path = test_df['path'].values\n",
        "    test_label = pd.get_dummies(test_df['label']).values\n",
        "    test_ds = Breed_Dataset(test_path, test_label, image_size=config.IMAGE_SIZE, batch_size=config.BATCH_SIZE, \n",
        "                        augmentor=None, shuffle=False, pre_func=config.PRE_FUNC)\n",
        "\n",
        "    evaluation_result = model.evaluate(test_ds)\n",
        "    print('evaluation_result:', evaluation_result)\n",
        "    \n",
        "    return model, evaluation_result\n",
        "\n",
        "model, evaluation_result = evaluate_model(model=eff1_model, test_df=test_df, config=Config)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pMiK8Y6jGQ_W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}